# -*- coding: utf-8 -*-
"""2.2 Multiclass Classification - Cyberbullying Tweets.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PsmAQHhRiyOBD6_uFs_KPjUGURozccQb

# Multiclass classification
**{"not_cyberbullying": 0, "religion": 1, "age": 2, "gender": 3, "ethnicity": 4}**
* Preprocessing
* Data preparation
* Classification models
* Explainability
"""

import csv
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

from stop_words import get_stop_words

from imblearn.over_sampling import RandomOverSampler
from imblearn.over_sampling import SMOTE

from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer
from sklearn.feature_selection import SelectKBest, chi2
from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import LinearSVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay

#from sklearn.metrics import plot_confusion_matrix

"""## Import dataset"""

df = pd.read_csv('Data/cleaned_tweet.csv')
df = df.drop(columns=['Unnamed: 0'])

df.shape

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Assuming df is your DataFrame containing the 'Type' column
type_counts = df["Type"].value_counts()

# Create a DataFrame from the value counts
type_counts_df = pd.DataFrame({'Type': type_counts.index, 'Count': type_counts.values})

# Order the DataFrame by the count
type_counts_df = type_counts_df.sort_values(by='Count', ascending=False)

sns.set(font_scale=1)

ax = sns.barplot(x='Type', y='Count', data=type_counts_df)

plt.title("Target variable counts in dataset")
plt.ylabel('Number of tweets')
plt.xlabel('Tweet Type')

# Adding the text labels
rects = ax.patches
for rect, label in zip(rects, type_counts_df['Count']):
    height = rect.get_height()
    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')

plt.show()

text_len = []
for text in df.Tweet:
    tweet_len = len(text.split())
    text_len.append(tweet_len)

df['text_len'] = text_len

plt.figure(figsize=(20,5))
ax = sns.countplot(x='text_len', data=df[df['text_len']<=30], palette='mako', hue= df['Type'])
plt.title('Count of tweets with less than 30 words', fontsize=20)
plt.yticks([100, 200, 300, 400], ['100', '200', '300', '400'],rotation=45)
plt.legend(['Not_cyberbullying', 'Religion', 'Age', 'Gender', 'Ethnicity'])
plt.ylabel('count')
plt.xlabel('')
plt.show()

#I remove all the tweet with less than 7 words
#df = df[df['text_len'] > 7]

plt.figure(figsize=(20,5))
ax = sns.countplot(x='text_len', data=df[(df['text_len']<=1000) & (df['text_len']>30)], palette='mako')
plt.title('Count of tweets with high number of words', fontsize=20)
plt.yticks([])
ax.bar_label(ax.containers[0])
plt.ylabel('count')
plt.xlabel('')
plt.show()

#I remove tweet with more than 60 words
df = df[df['text_len'] < 60]

np.max(df['text_len'])

df.sort_values(by=["text_len"], ascending=False)

"""## Dataset split"""

data = 'Tweet_tokenized'
target = 'Type'
X_train, X_test, y_train, y_test = train_test_split(df[data], df[target], test_size=0.33, random_state=42)

print("x_train ->", len(X_train), "record")
print("x_test  ->", len(X_test), "record")
print("y_train ->", len(y_train), "record")
print("y_test  ->", len(y_test), "record")

y_train.value_counts()

y_test.value_counts()

ros = RandomOverSampler()
X_train, y_train = ros.fit_resample(np.array(X_train).reshape(-1, 1), np.array(y_train).reshape(-1, 1))
train_os = pd.DataFrame(list(zip([x[0] for x in X_train], y_train)), columns = ['Tweet_tokenized', 'Type'])

train_os

X_train = train_os['Tweet_tokenized'].values
y_train = train_os['Type'].values

X_train

(unique, counts) = np.unique(y_train, return_counts=True)
np.asarray((unique, counts)).T

"""## Tokenization"""

vect = CountVectorizer()  # min_df: minimum number of words in a sentence
X_train_tok = vect.fit_transform(X_train)
X_test_tok =vect.transform(X_test)

"""## Feature selection"""

sel = SelectKBest(chi2, k=2000).fit(X_train_tok,y_train)
X_train_sel = sel.transform(X_train_tok)
X_test_sel = sel.transform(X_test_tok)

"""## Weigthing
Then we apply TF-IFD transformation to associate weigths to the different words based on their frequency (rarer words will be given more importance).


"""

tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_sel)
X_train_tf = tf_transformer.transform(X_train_sel)
X_test_tf = tf_transformer.transform(X_test_sel)

"""## Naive Bayes"""

nb_clf = MultinomialNB(alpha = 0.5)
nb_clf.fit(X_train_tf, y_train)
nb_pred = nb_clf.predict(X_test_tf)

print('Classification report:')
print(classification_report(y_test, nb_pred))
print('Confusion matrix:')
cm = confusion_matrix(y_test, nb_pred)
print(cm)

nb_scores = cross_val_score(nb_clf, X_train_tf, y_train, cv=5)

print("%0.2f accuracy with a standard deviation of %0.2f" % (nb_scores.mean(), nb_scores.std()))

"""## SVM
SVM is not thinked for a multiclass classification problem.

Instead, heuristic methods can be used to split a multi-class classification problem into multiple binary classification datasets and train a binary classification model each.
"""

svm_clf = LinearSVC().fit(X_train_tf, y_train)
svm_pred = svm_clf.predict(X_test_tf)

print('Classification report:')
print(classification_report(y_test, svm_pred))
print('Confusion matrix:')
svm_cm = confusion_matrix(y_test, svm_pred)
print(svm_cm)

"""##### SVM: One VS One"""

ovo_svm_clf = OneVsOneClassifier(LinearSVC()).fit(X_train_tf, y_train)
ovo_svm_pred = ovo_svm_clf.predict(X_test_tf)

print('Classification report:')
print(classification_report(y_test, ovo_svm_pred))

ovo_svm_scores = cross_val_score(ovo_svm_clf, X_train_tf, y_train, cv=5)
print("%0.2f accuracy with a standard deviation of %0.2f" % (ovo_svm_scores.mean(), ovo_svm_scores.std()))

#plot_confusion_matrix(ovo_svm_clf, X_test_tf, y_test)

"""**{"not_cyberbullying": 0, "religion": 1, "age": 2, "gender": 3, "ethnicity": 4}**

##### SVM: One VS RestClassifier
"""

ovr_svm_clf = OneVsRestClassifier(LinearSVC()).fit(X_train_tf, y_train)
ovr_svm_pred = ovr_svm_clf.predict(X_test_tf)

print('Classification report:')
print(classification_report(y_test, ovr_svm_pred))

ovr_svm_scores = cross_val_score(ovr_svm_clf, X_train_tf, y_train, cv=5)
print("%0.2f accuracy with a standard deviation of %0.2f" % (ovr_svm_scores.mean(), ovr_svm_scores.std()))

#plot_confusion_matrix(ovr_svm_clf, X_test_tf, y_test)

"""## Decision Tree"""

dt_clf = DecisionTreeClassifier(min_samples_leaf=20, min_samples_split=30).fit(X_train_tf, y_train)
dt_pred = dt_clf.predict(X_test_tf)

print('Classification report:')
print(classification_report(y_test, dt_pred))

dt_scores = cross_val_score(dt_clf, X_train_tf, y_train, cv=5)
print("%0.2f accuracy with a standard deviation of %0.2f" % (dt_scores.mean(), dt_scores.std()))

#plot_confusion_matrix(dt_clf, X_test_tf, y_test)

"""## Random Forest Classifier"""

rf_clf = RandomForestClassifier(min_samples_leaf=20, min_samples_split=30).fit(X_train_tf, y_train)
rf_pred = rf_clf.predict(X_test_tf)

print('Classification report:')
print(classification_report(y_test, rf_pred))

rf_scores = cross_val_score(rf_clf, X_train_tf, y_train, cv=5)
print("%0.2f accuracy with a standard deviation of %0.2f" % (rf_scores.mean(), rf_scores.std()))

#plot_confusion_matrix(rf_clf, X_test_tf, y_test)

"""## Explain results with LIME"""

class_name = list(set(x for x in train_os.Type))

## split to train and test
df_exp, df_val = train_test_split(train_os, test_size=0.1, random_state=42)

vectorizer = TfidfVectorizer(lowercase=False)
train_vectors = vectorizer.fit_transform(df_exp.Tweet_tokenized)
test_vectors = vectorizer.transform(df_val.Tweet_tokenized)

nb = MultinomialNB(alpha=.01)
nb = nb.fit(train_vectors, df_exp.Type)

import sklearn.metrics

pred = nb.predict(test_vectors)
sklearn.metrics.f1_score(df_val.Type, pred, average='weighted')

df_val.reset_index(inplace=True)
df_val = df_val.rename(columns={"index": "or_index"})

from lime import lime_text
from sklearn.pipeline import make_pipeline
c = make_pipeline(vectorizer, nb)

print(c.predict_proba([df_val.Tweet_tokenized[0]]).round(3))

from lime.lime_text import LimeTextExplainer
explainer = LimeTextExplainer(class_names=class_name)

idx = 0
exp = explainer.explain_instance(df_val.Tweet_tokenized[idx], c.predict_proba, num_features=6)
print('Document id: %d' % idx)
print('Tweet tokenized: ', df_val.Tweet_tokenized[idx])
print('Predicted class:', class_name[nb.predict(test_vectors[idx]).reshape(1,-1)[0,0]])
print('True class: %s' % class_name[df_val.Type[idx]])

exp = explainer.explain_instance(df_val.Tweet_tokenized[idx], c.predict_proba, num_features=6, top_labels=2)
exp.available_labels()

print ('Explanation for class %s' % class_name[exp.available_labels()[0]])
print ('\n'.join(map(str, exp.as_list(label=exp.available_labels()[0]))))
print ()
print ('Explanation for class %s' % class_name[exp.available_labels()[1]])
print ('\n'.join(map(str, exp.as_list(label=exp.available_labels()[1]))))

row = df[df['Tweet_tokenized'] == df_val.Tweet_tokenized[idx]]
row.Tweet

#{0: not_bully, 1: religion , 2: age, 3: gender, 4: ethnicity}
exp.show_in_notebook(text = df_val.Tweet_tokenized[idx])

